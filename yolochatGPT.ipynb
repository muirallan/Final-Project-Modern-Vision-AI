{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "44e1419c",
      "metadata": {
        "id": "44e1419c"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# YOLOv5\n",
        "\n",
        "*Author: Ultralytics*\n",
        "\n",
        "**Ultralytics YOLOv5 🚀 for object detection, instance segmentation and image classification.**\n",
        "\n",
        "_ | _\n",
        "- | -\n",
        "![alt](https://pytorch.org/assets/images/ultralytics_yolov5_img1.png) | ![alt](https://pytorch.org/assets/images/ultralytics_yolov5_img2.png)\n",
        "\n",
        "\n",
        "## Before You Start\n",
        "\n",
        "Start from a **Python>=3.8** environment with **PyTorch>=1.7** installed. To install PyTorch see [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/). To install YOLOv5 dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e1de70e2",
      "metadata": {
        "id": "e1de70e2",
        "outputId": "7baaa8de-86bb-4ade-85bc-34897a4f522b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install -U ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install YOLOv8 from ultralytics\n",
        "!pip install ultralytics\n",
        "\n",
        "# Install Flask and Flask-Ngrok for serving the app for future work\n",
        "#!pip install flask flask-ngrok\n",
        "\n",
        "# Install OpenCV for image processing\n",
        "!pip install opencv-python\n",
        "\n",
        "# Install Pillow for image handling\n",
        "!pip install pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihoz8vd0IVTZ",
        "outputId": "00cddcaa-d3c4-42b1-e750-7bf0119ea833"
      },
      "id": "Ihoz8vd0IVTZ",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import logging\n",
        "import base64\n"
      ],
      "metadata": {
        "id": "6FiRiT0qItGA"
      },
      "id": "6FiRiT0qItGA",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## HERE IS THE INPUT VIDEO. YOU SET THIS.\n",
        "input_video_path = '/content/Calssroom.MOV'\n",
        "\n",
        "# API Key from platform.openai.com. YOU SET THIS TO YOUR API KEY.\n",
        "api_key=\"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\""
      ],
      "metadata": {
        "id": "7gb8elbQIx8L"
      },
      "id": "7gb8elbQIx8L",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## OUTPUT FILES. AUTOMATICALLY SET.\n",
        "output_framestext_file=input_video_path+\"_frametext_out.txt\"\n",
        "output_summary_file=input_video_path+\"_summary_out.txt\"\n",
        "\n",
        "## Frames folder. AUTOMATICALLY SET.\n",
        "output_frames_dir=\"frames\""
      ],
      "metadata": {
        "id": "QEDauBCqqpOI"
      },
      "id": "QEDauBCqqpOI",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG, filename='video_labeler.log', filemode='w', format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "console = logging.StreamHandler()\n",
        "console.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "console.setFormatter(formatter)\n",
        "logging.getLogger('').addHandler(console)"
      ],
      "metadata": {
        "id": "tes00KiAsbbh"
      },
      "id": "tes00KiAsbbh",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Given an image the following function\n",
        "## returns OpenAI's response.\n",
        "## The function uses the global variable api_key\n",
        "## to communicate with OpenAI\n",
        "\n",
        "def generate_image_description(image_path):\n",
        "    with requests.Session() as session:\n",
        "        # Convert image to base64\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "        headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "          \"model\": \"gpt-4o\",\n",
        "          \"messages\": [\n",
        "            {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": \"What’s in this image?\"\n",
        "                },\n",
        "                {\n",
        "                  \"type\": \"image_url\",\n",
        "                  \"image_url\": {\n",
        "                    \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
        "                  }\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          ],\n",
        "          \"max_tokens\": 300\n",
        "        }\n",
        "\n",
        "        #response = requests.post(\"https://api.openai.com/v1/chat/completions\",\n",
        "        #                         headers=headers, json=payload)\n",
        "        # I will create a session for each image.\n",
        "        response = session.post(\"https://api.openai.com/v1/chat/completions\",\n",
        "                                    headers=headers, json=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            description = response.json()['choices'][0]['message']['content'].strip()\n",
        "            return description\n",
        "        else:\n",
        "            logging.error(f\"OpenAI API error: {response.status_code}, {response.text}\")\n",
        "            return \"Error in getting description\""
      ],
      "metadata": {
        "id": "sWPpR0PwskEp"
      },
      "id": "sWPpR0PwskEp",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the output_framestext_file as the input parameter\n",
        "# the function returns the summary text for all the frames.\n",
        "# The function uses OpenAI API Key (in global variable api_key)\n",
        "\n",
        "def summarizeViaOpenAI(frames_description_file):\n",
        "    with requests.Session() as session:\n",
        "        try:\n",
        "            with open(frames_description_file,\n",
        "                      'r', encoding='utf-8',\n",
        "                      errors='replace') as file:\n",
        "                file_content = file.read()\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "\n",
        "        headers = {\n",
        "          \"Content-Type\": \"application/json\",\n",
        "          \"Authorization\": f\"Bearer {api_key}\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "          \"model\": \"gpt-4o\",\n",
        "          \"messages\": [\n",
        "            {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": \"The content has descriptions of frames in a video. Please summarize the video.\"\n",
        "                },\n",
        "                {\n",
        "                  \"type\": \"text\",\n",
        "                  \"text\": file_content\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          ],\n",
        "          \"max_tokens\": 300\n",
        "        }\n",
        "\n",
        "        response = session.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "        return response.json()['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "LisnbKJcswEG"
      },
      "id": "LisnbKJcswEG",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "if not cap.isOpened():\n",
        "    raise Exception(\n",
        "        f\"Error: Could not open input video file: {input_video_path}\")"
      ],
      "metadata": {
        "id": "JLKRneDas4mt"
      },
      "id": "JLKRneDas4mt",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_interval = int(fps * 2)  # 2 seconds interval"
      ],
      "metadata": {
        "id": "BrGfzmZKs_kf"
      },
      "id": "BrGfzmZKs_kf",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an output directory for frames\n",
        "os.makedirs(output_frames_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "FOQJ20jZtC9N"
      },
      "id": "FOQJ20jZtC9N",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the text file to write detected objects.\n",
        "# Also, save the frames that are sent to OpenAI\n",
        "with open(output_framestext_file,\n",
        "          \"w\") as file, tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "         desc=\"Processing frames\") as pbar:\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_interval == 0:\n",
        "            frame_path = os.path.join(output_frames_dir, f\"frame_{frame_count}.jpg\")\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "\n",
        "            # Send frame to OpenAI API\n",
        "            try:\n",
        "                description = generate_image_description(frame_path)\n",
        "                # Write object descriptions to file\n",
        "                file.write(f\"Frame {frame_count}: {description}\\n\")\n",
        "                file.flush()\n",
        "                logging.info(f\"Processed frame {frame_count}: {description}\")\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing frame {frame_count} with OpenAI API: {e}\")\n",
        "\n",
        "        frame_count += 1\n",
        "        pbar.update(1)\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "C0ODOLoEtIBK",
        "outputId": "545e4796-e322-48e6-e8da-a59f7fe24a0f"
      },
      "id": "C0ODOLoEtIBK",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing frames: 100%|██████████| 240/240 [00:28<00:00,  8.54it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-b0957454bc95>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarizeViaOpenAI(output_framestext_file)\n",
        "print(\"THE SUMMARY OF THE VIDEO IS AS FOLLOWS: \")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEbkXxd7tPaC",
        "outputId": "0b5212b5-0779-4e95-d0f5-a7c72e40b38c"
      },
      "id": "pEbkXxd7tPaC",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE SUMMARY OF THE VIDEO IS AS FOLLOWS: \n",
            "The video appears to depict a casual gathering of people in an indoor setting that resembles a classroom or office. Throughout the frames, individuals are shown engaged in interactions, either sitting or standing around tables filled with personal belongings and office supplies, such as notebooks, smartphones, disinfecting wipes, and keys. The environment features elements like bulletin boards, computer monitors, and posters, contributing to a professional yet relaxed atmosphere. The people in the video appear to be having informal conversations and some are seen eating snacks, suggesting a friendly and casual meeting or group activity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Write the summary to the file output_summary_file\n",
        "try:\n",
        "    with open(output_summary_file,\n",
        "              'w', encoding='utf-8') as summaryfile:\n",
        "        summaryfile.write(summary)\n",
        "        summaryfile.flush()\n",
        "    print(f\"Content successfully written to {output_summary_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3Y9JtaqtUyE",
        "outputId": "72a20271-6bcd-4ab3-a0ad-1919086aeb81"
      },
      "id": "U3Y9JtaqtUyE",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content successfully written to /content/Calssroom.MOV_summary_out.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "import torchvision\n",
        "import logging\n",
        "import gc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qony0PRquQA-",
        "outputId": "809676b0-8d1d-4268-e1d1-187a5baebba5"
      },
      "id": "Qony0PRquQA-",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## HERE IS THE INPUT VIDEO. SET THIS\n",
        "input_video_path = '/content/Calssroom.MOV'\n",
        "\n",
        "## OUTPUT FILES. AUTOMATICALLY SET.\n",
        "output_video_path = input_video_path+\"_out.avi\"\n",
        "output_text_file=input_video_path+\"_out.txt\"\n"
      ],
      "metadata": {
        "id": "AhvN1-7UuUjG"
      },
      "id": "AhvN1-7UuUjG",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    filename='video_labeler.log',\n",
        "    filemode='w',\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "console = logging.StreamHandler()\n",
        "console.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter(\n",
        "    '%(asctime)s - %(levelname)s - %(message)s')\n",
        "console.setFormatter(formatter)\n",
        "logging.getLogger('').addHandler(console)\n"
      ],
      "metadata": {
        "id": "UlwlqQdyun09"
      },
      "id": "UlwlqQdyun09",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Load YOLOv8 model\n",
        "    model = YOLO(\"yolov8n.pt\")  # You can replace \"YOLOv8x.pt\"  with other YOLOv8 models like yolov8s.pt, etc. https://docs.ultralytics.com/tasks/detect/#models\n",
        "    logging.info(\"YOLOv8 model loaded successfully.\")\n",
        "\n",
        "    # Load video\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise Exception(\n",
        "            f\"Error: Could not open input video file: {input_video_path}\")\n",
        "\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "    out = cv2.VideoWriter(\n",
        "        output_video_path, fourcc, fps, (width, height))\n",
        "    if not out.isOpened():\n",
        "        raise Exception(\n",
        "            f\"Error: Could not open output video file for writing: {output_video_path}\")\n",
        "\n",
        "    logging.info(\n",
        "        f\"VideoWriter opened successfully: {out.isOpened()}\")\n",
        "\n",
        "    # Get total number of frames in the video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Open the text file to write detected objects\n",
        "    with open(output_text_file, \"w\") as file, tqdm(total=total_frames,\n",
        "         desc=\"Processing frames\") as pbar:\n",
        "        frame_count = 0\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Detecting objects using YOLOv8\n",
        "            try:\n",
        "                results = model(frame, device='cpu')  # Use CPU for inference\n",
        "                detected_objects = []\n",
        "\n",
        "                for result in results:\n",
        "                    boxes = result.boxes  # Boxes object for bbox outputs\n",
        "\n",
        "                    if len(boxes.xyxy) > 0:\n",
        "                        boxes_tensor = boxes.xyxy.to('cpu')\n",
        "                        scores = boxes.conf.to('cpu')\n",
        "                        nms_indices = torchvision.ops.nms(boxes_tensor, scores, 0.5)\n",
        "\n",
        "                        for idx in nms_indices:\n",
        "                            x1, y1, x2, y2 = boxes.xyxy[idx].tolist()\n",
        "                            confidence = boxes.conf[idx].item()\n",
        "                            class_id = int(boxes.cls[idx].item())\n",
        "                            label = model.names[class_id]\n",
        "                            detected_objects.append(label)\n",
        "\n",
        "                            # Draw bounding box and label on the frame\n",
        "                            color = (0, 255, 0)\n",
        "                            cv2.rectangle(frame,\n",
        "                                          (int(x1), int(y1)),\n",
        "                                          (int(x2), int(y2)),\n",
        "                                          color, 2)\n",
        "                            cv2.putText(frame, label,\n",
        "                                        (int(x1), int(y1) - 10),\n",
        "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "                out.write(frame)  # Write the frame to the video file\n",
        "\n",
        "                # Write detected objects to file\n",
        "                file.write(\n",
        "                    f\"Frame {int(cap.get(cv2.CAP_PROP_POS_FRAMES))}: {', '.join(detected_objects)}\\n\")\n",
        "                file.flush()  # Flush the file buffer to ensure data is written to disk\n",
        "\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)  # Update the progress bar\n",
        "\n",
        "                # Debugging output every 100 frames\n",
        "                if frame_count % 100 == 0:\n",
        "                    logging.info(f\"Processed {frame_count}/{total_frames} frames.\")\n",
        "\n",
        "                # Clear memory\n",
        "                del results, detected_objects\n",
        "                gc.collect()\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing frame {frame_count}: {e}\")\n",
        "                continue\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    print(\"Output video file: \", output_video_path)\n",
        "    print(\"Output object list file: \", output_text_file)\n",
        "\n",
        "    logging.info(\"Processing complete. Output video and detected objects file have been created.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh1kmHm3usMX",
        "outputId": "fe0085bc-a56b-4fed-8d70-d1a07c6d07ad"
      },
      "id": "Qh1kmHm3usMX",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   0%|          | 0/240 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 cup, 1 dining table, 1 book, 258.4ms\n",
            "Speed: 19.2ms preprocess, 258.4ms inference, 28.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   0%|          | 1/240 [00:02<08:04,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 bottle, 1 dining table, 1 book, 105.2ms\n",
            "Speed: 7.5ms preprocess, 105.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   1%|          | 2/240 [00:02<03:59,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 bottle, 1 dining table, 1 book, 108.3ms\n",
            "Speed: 3.7ms preprocess, 108.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   1%|▏         | 3/240 [00:02<02:40,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 bottle, 1 bowl, 1 dining table, 1 remote, 1 cell phone, 1 book, 105.1ms\n",
            "Speed: 3.2ms preprocess, 105.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   2%|▏         | 4/240 [00:02<02:02,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 bottle, 1 dining table, 1 book, 114.9ms\n",
            "Speed: 3.1ms preprocess, 114.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   2%|▏         | 5/240 [00:03<01:43,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 bottle, 1 dining table, 2 books, 104.0ms\n",
            "Speed: 3.3ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   2%|▎         | 6/240 [00:03<01:29,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 bottle, 1 dining table, 1 cell phone, 1 book, 102.0ms\n",
            "Speed: 5.5ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   3%|▎         | 7/240 [00:03<01:21,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 dining table, 1 book, 95.3ms\n",
            "Speed: 3.3ms preprocess, 95.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   3%|▎         | 8/240 [00:04<01:15,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 dining table, 1 cell phone, 2 books, 90.3ms\n",
            "Speed: 4.0ms preprocess, 90.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   4%|▍         | 9/240 [00:04<01:11,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 bowl, 1 dining table, 1 cell phone, 1 book, 95.7ms\n",
            "Speed: 4.8ms preprocess, 95.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   4%|▍         | 10/240 [00:04<01:09,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 handbag, 1 bottle, 1 dining table, 1 remote, 1 cell phone, 1 book, 88.9ms\n",
            "Speed: 5.4ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   5%|▍         | 11/240 [00:04<01:06,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 dining table, 1 cell phone, 1 book, 100.2ms\n",
            "Speed: 2.9ms preprocess, 100.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   5%|▌         | 12/240 [00:05<01:05,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 dining table, 1 cell phone, 2 books, 102.4ms\n",
            "Speed: 3.2ms preprocess, 102.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   5%|▌         | 13/240 [00:05<01:05,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 1 cell phone, 1 book, 106.7ms\n",
            "Speed: 3.5ms preprocess, 106.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   6%|▌         | 14/240 [00:05<01:04,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 dining table, 2 cell phones, 1 book, 91.0ms\n",
            "Speed: 3.5ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   6%|▋         | 15/240 [00:05<01:03,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 2 bottles, 1 cup, 1 dining table, 1 cell phone, 2 books, 118.2ms\n",
            "Speed: 3.0ms preprocess, 118.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   7%|▋         | 16/240 [00:06<01:04,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 dining table, 2 books, 110.8ms\n",
            "Speed: 3.9ms preprocess, 110.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   7%|▋         | 17/240 [00:06<01:04,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 dining table, 2 books, 93.0ms\n",
            "Speed: 3.3ms preprocess, 93.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   8%|▊         | 18/240 [00:06<01:02,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 1 cell phone, 1 book, 100.4ms\n",
            "Speed: 5.1ms preprocess, 100.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   8%|▊         | 19/240 [00:07<01:02,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 remote, 1 book, 96.7ms\n",
            "Speed: 3.3ms preprocess, 96.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   8%|▊         | 20/240 [00:07<01:02,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 1 remote, 1 book, 111.8ms\n",
            "Speed: 3.4ms preprocess, 111.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   9%|▉         | 21/240 [00:07<01:03,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 1 remote, 1 book, 88.6ms\n",
            "Speed: 4.4ms preprocess, 88.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:   9%|▉         | 22/240 [00:07<01:01,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 cup, 1 remote, 100.4ms\n",
            "Speed: 3.4ms preprocess, 100.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  10%|▉         | 23/240 [00:08<01:01,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 bottle, 1 cup, 1 remote, 1 book, 140.0ms\n",
            "Speed: 3.9ms preprocess, 140.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  10%|█         | 24/240 [00:08<01:03,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 99.3ms\n",
            "Speed: 2.9ms preprocess, 99.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  10%|█         | 25/240 [00:08<01:01,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 bottle, 1 cup, 1 book, 85.0ms\n",
            "Speed: 3.9ms preprocess, 85.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  11%|█         | 26/240 [00:09<00:59,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 cup, 102.6ms\n",
            "Speed: 2.9ms preprocess, 102.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  11%|█▏        | 27/240 [00:09<01:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 cup, 1 book, 101.5ms\n",
            "Speed: 3.5ms preprocess, 101.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  12%|█▏        | 28/240 [00:09<01:00,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 bottle, 1 cup, 1 remote, 1 cell phone, 1 book, 95.1ms\n",
            "Speed: 3.3ms preprocess, 95.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  12%|█▏        | 29/240 [00:09<00:59,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 bottle, 1 cup, 1 book, 85.2ms\n",
            "Speed: 3.2ms preprocess, 85.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  12%|█▎        | 30/240 [00:10<00:57,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 bottle, 1 cup, 1 dining table, 101.9ms\n",
            "Speed: 5.6ms preprocess, 101.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  13%|█▎        | 31/240 [00:10<00:58,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 98.8ms\n",
            "Speed: 5.0ms preprocess, 98.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  13%|█▎        | 32/240 [00:10<00:58,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 dining table, 1 remote, 1 book, 96.4ms\n",
            "Speed: 3.3ms preprocess, 96.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  14%|█▍        | 33/240 [00:11<00:57,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 cup, 1 dining table, 1 remote, 1 book, 94.1ms\n",
            "Speed: 3.9ms preprocess, 94.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  14%|█▍        | 34/240 [00:11<00:56,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 bottle, 1 dining table, 1 remote, 1 book, 147.8ms\n",
            "Speed: 3.2ms preprocess, 147.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  15%|█▍        | 35/240 [00:11<01:03,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 bottle, 1 dining table, 1 book, 139.8ms\n",
            "Speed: 3.0ms preprocess, 139.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  15%|█▌        | 36/240 [00:12<01:07,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 bottle, 1 dining table, 1 book, 147.8ms\n",
            "Speed: 6.4ms preprocess, 147.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  15%|█▌        | 37/240 [00:12<01:10,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 dining table, 1 book, 126.3ms\n",
            "Speed: 6.8ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  16%|█▌        | 38/240 [00:12<01:11,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 1 book, 131.9ms\n",
            "Speed: 3.3ms preprocess, 131.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  16%|█▋        | 39/240 [00:13<01:13,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 handbag, 1 cup, 1 dining table, 1 book, 159.0ms\n",
            "Speed: 3.1ms preprocess, 159.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  17%|█▋        | 40/240 [00:13<01:16,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 dining table, 1 book, 146.0ms\n",
            "Speed: 3.1ms preprocess, 146.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  17%|█▋        | 41/240 [00:14<01:16,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 bottle, 1 cup, 1 dining table, 1 book, 99.3ms\n",
            "Speed: 4.0ms preprocess, 99.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  18%|█▊        | 42/240 [00:14<01:10,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 bottle, 1 dining table, 1 book, 101.7ms\n",
            "Speed: 2.9ms preprocess, 101.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  18%|█▊        | 43/240 [00:14<01:06,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 bottle, 1 dining table, 1 tv, 1 book, 94.2ms\n",
            "Speed: 2.9ms preprocess, 94.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  18%|█▊        | 44/240 [00:14<01:02,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 backpack, 1 bottle, 1 dining table, 1 tv, 1 book, 94.8ms\n",
            "Speed: 3.3ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  19%|█▉        | 45/240 [00:15<00:59,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 bottle, 1 dining table, 1 tv, 1 book, 112.4ms\n",
            "Speed: 3.6ms preprocess, 112.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  19%|█▉        | 46/240 [00:15<00:59,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 cup, 1 dining table, 1 book, 111.5ms\n",
            "Speed: 2.8ms preprocess, 111.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  20%|█▉        | 47/240 [00:15<00:58,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 bottle, 1 dining table, 1 cell phone, 1 book, 110.7ms\n",
            "Speed: 3.6ms preprocess, 110.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  20%|██        | 48/240 [00:16<00:57,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 1 book, 96.4ms\n",
            "Speed: 3.5ms preprocess, 96.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  20%|██        | 49/240 [00:16<00:56,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 92.0ms\n",
            "Speed: 3.4ms preprocess, 92.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  21%|██        | 50/240 [00:16<00:55,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 103.1ms\n",
            "Speed: 2.9ms preprocess, 103.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  21%|██▏       | 51/240 [00:16<00:54,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 1 book, 92.5ms\n",
            "Speed: 4.0ms preprocess, 92.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  22%|██▏       | 52/240 [00:17<00:53,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 cup, 1 dining table, 1 book, 115.2ms\n",
            "Speed: 2.9ms preprocess, 115.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  22%|██▏       | 53/240 [00:17<00:53,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 98.6ms\n",
            "Speed: 3.5ms preprocess, 98.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  22%|██▎       | 54/240 [00:17<00:53,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 chair, 1 dining table, 1 book, 99.6ms\n",
            "Speed: 3.3ms preprocess, 99.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  23%|██▎       | 55/240 [00:18<00:52,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 chair, 1 dining table, 1 book, 119.0ms\n",
            "Speed: 6.0ms preprocess, 119.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  23%|██▎       | 56/240 [00:18<00:52,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 1 book, 122.2ms\n",
            "Speed: 4.0ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  24%|██▍       | 57/240 [00:18<00:54,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 96.5ms\n",
            "Speed: 3.5ms preprocess, 96.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  24%|██▍       | 58/240 [00:18<00:52,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 104.2ms\n",
            "Speed: 4.4ms preprocess, 104.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  25%|██▍       | 59/240 [00:19<00:52,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 110.4ms\n",
            "Speed: 3.9ms preprocess, 110.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  25%|██▌       | 60/240 [00:19<00:52,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 99.0ms\n",
            "Speed: 3.8ms preprocess, 99.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  25%|██▌       | 61/240 [00:19<00:51,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 87.7ms\n",
            "Speed: 3.2ms preprocess, 87.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  26%|██▌       | 62/240 [00:20<00:49,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 96.5ms\n",
            "Speed: 2.9ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  26%|██▋       | 63/240 [00:20<00:48,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 keyboard, 112.9ms\n",
            "Speed: 3.6ms preprocess, 112.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  27%|██▋       | 64/240 [00:20<00:50,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 cup, 1 dining table, 101.1ms\n",
            "Speed: 3.0ms preprocess, 101.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  27%|██▋       | 65/240 [00:20<00:49,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 cup, 1 dining table, 1 keyboard, 86.8ms\n",
            "Speed: 4.1ms preprocess, 86.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  28%|██▊       | 66/240 [00:21<00:48,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 111.7ms\n",
            "Speed: 3.3ms preprocess, 111.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  28%|██▊       | 67/240 [00:21<00:48,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 122.9ms\n",
            "Speed: 9.4ms preprocess, 122.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  28%|██▊       | 68/240 [00:21<00:49,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 2 chairs, 1 dining table, 95.5ms\n",
            "Speed: 4.1ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  29%|██▉       | 69/240 [00:22<00:48,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 92.7ms\n",
            "Speed: 3.9ms preprocess, 92.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  29%|██▉       | 70/240 [00:22<00:47,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 cup, 1 knife, 1 chair, 1 dining table, 1 cell phone, 101.8ms\n",
            "Speed: 3.2ms preprocess, 101.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  30%|██▉       | 71/240 [00:22<00:48,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 99.7ms\n",
            "Speed: 3.7ms preprocess, 99.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  30%|███       | 72/240 [00:22<00:47,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 87.6ms\n",
            "Speed: 4.0ms preprocess, 87.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  30%|███       | 73/240 [00:23<00:46,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 bottle, 2 chairs, 1 dining table, 1 tv, 113.9ms\n",
            "Speed: 3.6ms preprocess, 113.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  31%|███       | 74/240 [00:23<00:47,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 chair, 1 tv, 112.4ms\n",
            "Speed: 4.1ms preprocess, 112.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  31%|███▏      | 75/240 [00:23<00:47,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 1 tv, 95.5ms\n",
            "Speed: 3.4ms preprocess, 95.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  32%|███▏      | 76/240 [00:24<00:46,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 154.0ms\n",
            "Speed: 3.4ms preprocess, 154.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  32%|███▏      | 77/240 [00:24<00:50,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 129.3ms\n",
            "Speed: 3.2ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  32%|███▎      | 78/240 [00:24<00:54,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 cup, 1 chair, 1 remote, 141.1ms\n",
            "Speed: 3.4ms preprocess, 141.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  33%|███▎      | 79/240 [00:25<00:55,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 cup, 2 chairs, 1 dining table, 153.4ms\n",
            "Speed: 3.6ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  33%|███▎      | 80/240 [00:25<00:56,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 cup, 2 chairs, 1 book, 152.4ms\n",
            "Speed: 3.3ms preprocess, 152.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  34%|███▍      | 81/240 [00:25<00:57,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 bottle, 1 chair, 1 dining table, 1 book, 145.1ms\n",
            "Speed: 3.3ms preprocess, 145.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  34%|███▍      | 82/240 [00:26<00:58,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 backpack, 1 chair, 148.7ms\n",
            "Speed: 5.3ms preprocess, 148.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  35%|███▍      | 83/240 [00:26<01:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 backpack, 1 handbag, 1 chair, 1 book, 98.9ms\n",
            "Speed: 4.8ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  35%|███▌      | 84/240 [00:27<00:56,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 backpack, 1 chair, 98.8ms\n",
            "Speed: 3.6ms preprocess, 98.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  35%|███▌      | 85/240 [00:27<00:52,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 chair, 1 tv, 1 book, 102.0ms\n",
            "Speed: 3.2ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  36%|███▌      | 86/240 [00:27<00:49,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 backpack, 1 handbag, 1 chair, 1 tv, 110.8ms\n",
            "Speed: 3.6ms preprocess, 110.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  36%|███▋      | 87/240 [00:27<00:48,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 chair, 114.2ms\n",
            "Speed: 5.5ms preprocess, 114.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  37%|███▋      | 88/240 [00:28<00:46,  3.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 handbag, 1 chair, 1 book, 115.0ms\n",
            "Speed: 4.6ms preprocess, 115.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  37%|███▋      | 89/240 [00:28<00:46,  3.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 handbag, 1 suitcase, 1 chair, 1 book, 95.1ms\n",
            "Speed: 2.8ms preprocess, 95.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  38%|███▊      | 90/240 [00:28<00:44,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 handbag, 1 chair, 103.4ms\n",
            "Speed: 3.2ms preprocess, 103.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  38%|███▊      | 91/240 [00:29<00:44,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 backpack, 1 suitcase, 1 chair, 104.8ms\n",
            "Speed: 2.8ms preprocess, 104.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  38%|███▊      | 92/240 [00:29<00:42,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 7 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 104.3ms\n",
            "Speed: 3.4ms preprocess, 104.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  39%|███▉      | 93/240 [00:29<00:43,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 7 persons, 1 suitcase, 1 chair, 1 tv, 93.4ms\n",
            "Speed: 7.3ms preprocess, 93.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  39%|███▉      | 94/240 [00:29<00:42,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 suitcase, 1 chair, 1 tv, 1 book, 94.8ms\n",
            "Speed: 4.1ms preprocess, 94.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  40%|███▉      | 95/240 [00:30<00:41,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 1 book, 117.2ms\n",
            "Speed: 2.8ms preprocess, 117.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  40%|████      | 96/240 [00:30<00:41,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 tvs, 2 laptops, 99.9ms\n",
            "Speed: 3.7ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  40%|████      | 97/240 [00:30<00:41,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 3 chairs, 104.5ms\n",
            "Speed: 3.5ms preprocess, 104.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  41%|████      | 98/240 [00:31<00:40,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 2 chairs, 1 tv, 1 laptop, 98.8ms\n",
            "Speed: 3.1ms preprocess, 98.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  41%|████▏     | 99/240 [00:31<00:39,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 2 chairs, 2 laptops, 107.1ms\n",
            "Speed: 3.2ms preprocess, 107.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  42%|████▏     | 100/240 [00:31<00:40,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 2 handbags, 1 suitcase, 2 chairs, 1 tv, 1 laptop, 112.0ms\n",
            "Speed: 3.2ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  42%|████▏     | 101/240 [00:31<00:40,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 7 persons, 1 handbag, 1 suitcase, 2 chairs, 2 tvs, 106.3ms\n",
            "Speed: 3.6ms preprocess, 106.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  42%|████▎     | 102/240 [00:32<00:39,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 103.7ms\n",
            "Speed: 4.8ms preprocess, 103.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  43%|████▎     | 103/240 [00:32<00:39,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 104.6ms\n",
            "Speed: 3.3ms preprocess, 104.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  43%|████▎     | 104/240 [00:32<00:39,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 suitcase, 2 chairs, 2 tvs, 2 laptops, 96.1ms\n",
            "Speed: 3.5ms preprocess, 96.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  44%|████▍     | 105/240 [00:33<00:38,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 3 chairs, 2 tvs, 2 laptops, 93.2ms\n",
            "Speed: 4.6ms preprocess, 93.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  44%|████▍     | 106/240 [00:33<00:37,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 2 chairs, 1 tv, 2 laptops, 105.1ms\n",
            "Speed: 3.6ms preprocess, 105.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  45%|████▍     | 107/240 [00:33<00:38,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 100.6ms\n",
            "Speed: 3.6ms preprocess, 100.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  45%|████▌     | 108/240 [00:33<00:37,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 122.7ms\n",
            "Speed: 3.7ms preprocess, 122.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  45%|████▌     | 109/240 [00:34<00:37,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 2 chairs, 2 tvs, 2 laptops, 103.2ms\n",
            "Speed: 3.9ms preprocess, 103.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  46%|████▌     | 110/240 [00:34<00:37,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 93.4ms\n",
            "Speed: 3.6ms preprocess, 93.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  46%|████▋     | 111/240 [00:34<00:36,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 2 tvs, 2 laptops, 93.4ms\n",
            "Speed: 3.3ms preprocess, 93.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  47%|████▋     | 112/240 [00:35<00:36,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 2 chairs, 2 tvs, 2 laptops, 103.6ms\n",
            "Speed: 3.9ms preprocess, 103.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  47%|████▋     | 113/240 [00:35<00:35,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 tv, 1 laptop, 99.7ms\n",
            "Speed: 6.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  48%|████▊     | 114/240 [00:35<00:35,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 87.2ms\n",
            "Speed: 3.2ms preprocess, 87.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  48%|████▊     | 115/240 [00:35<00:35,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 1 laptop, 101.0ms\n",
            "Speed: 3.5ms preprocess, 101.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  48%|████▊     | 116/240 [00:36<00:34,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 laptops, 109.2ms\n",
            "Speed: 3.5ms preprocess, 109.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  49%|████▉     | 117/240 [00:36<00:34,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 cup, 1 chair, 1 tv, 1 laptop, 91.3ms\n",
            "Speed: 3.2ms preprocess, 91.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  49%|████▉     | 118/240 [00:36<00:34,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 131.4ms\n",
            "Speed: 7.6ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  50%|████▉     | 119/240 [00:37<00:36,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 158.9ms\n",
            "Speed: 5.7ms preprocess, 158.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  50%|█████     | 120/240 [00:37<00:39,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 128.4ms\n",
            "Speed: 11.6ms preprocess, 128.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  50%|█████     | 121/240 [00:37<00:40,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 2 tvs, 127.2ms\n",
            "Speed: 3.2ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  51%|█████     | 122/240 [00:38<00:39,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 133.2ms\n",
            "Speed: 3.4ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  51%|█████▏    | 123/240 [00:38<00:40,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 couch, 1 tv, 2 laptops, 153.1ms\n",
            "Speed: 3.4ms preprocess, 153.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  52%|█████▏    | 124/240 [00:38<00:42,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 143.4ms\n",
            "Speed: 3.5ms preprocess, 143.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  52%|█████▏    | 125/240 [00:39<00:42,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 2 chairs, 2 tvs, 1 laptop, 130.3ms\n",
            "Speed: 5.7ms preprocess, 130.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  52%|█████▎    | 126/240 [00:39<00:42,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 laptops, 87.6ms\n",
            "Speed: 3.0ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  53%|█████▎    | 127/240 [00:40<00:39,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 1 tv, 2 laptops, 101.5ms\n",
            "Speed: 3.5ms preprocess, 101.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  53%|█████▎    | 128/240 [00:40<00:36,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 100.4ms\n",
            "Speed: 2.9ms preprocess, 100.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  54%|█████▍    | 129/240 [00:40<00:35,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 98.3ms\n",
            "Speed: 5.6ms preprocess, 98.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  54%|█████▍    | 130/240 [00:40<00:33,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 1 tv, 2 laptops, 93.0ms\n",
            "Speed: 3.2ms preprocess, 93.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  55%|█████▍    | 131/240 [00:41<00:31,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 1 mouse, 116.3ms\n",
            "Speed: 4.3ms preprocess, 116.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  55%|█████▌    | 132/240 [00:41<00:31,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 1 chair, 2 tvs, 2 laptops, 1 mouse, 1 book, 94.1ms\n",
            "Speed: 3.8ms preprocess, 94.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  55%|█████▌    | 133/240 [00:41<00:31,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 1 chair, 2 tvs, 2 laptops, 1 mouse, 1 book, 87.6ms\n",
            "Speed: 3.2ms preprocess, 87.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  56%|█████▌    | 134/240 [00:41<00:30,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 cup, 3 tvs, 3 laptops, 1 mouse, 96.8ms\n",
            "Speed: 2.8ms preprocess, 96.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  56%|█████▋    | 135/240 [00:42<00:29,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 3 tvs, 3 laptops, 1 mouse, 127.3ms\n",
            "Speed: 3.5ms preprocess, 127.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  57%|█████▋    | 136/240 [00:42<00:30,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 3 tvs, 2 laptops, 1 mouse, 109.0ms\n",
            "Speed: 3.1ms preprocess, 109.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  57%|█████▋    | 137/240 [00:42<00:29,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 3 tvs, 1 laptop, 1 mouse, 91.5ms\n",
            "Speed: 3.4ms preprocess, 91.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  57%|█████▊    | 138/240 [00:43<00:28,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 1 chair, 4 tvs, 2 laptops, 1 mouse, 113.4ms\n",
            "Speed: 6.2ms preprocess, 113.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  58%|█████▊    | 139/240 [00:43<00:29,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 3 tvs, 2 laptops, 1 mouse, 95.0ms\n",
            "Speed: 3.3ms preprocess, 95.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  58%|█████▊    | 140/240 [00:43<00:28,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 cup, 3 tvs, 2 laptops, 1 mouse, 95.3ms\n",
            "Speed: 4.1ms preprocess, 95.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  59%|█████▉    | 141/240 [00:43<00:28,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 cup, 3 tvs, 1 laptop, 1 mouse, 93.8ms\n",
            "Speed: 3.0ms preprocess, 93.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  59%|█████▉    | 142/240 [00:44<00:27,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 3 tvs, 2 laptops, 116.3ms\n",
            "Speed: 3.2ms preprocess, 116.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  60%|█████▉    | 143/240 [00:44<00:27,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 suitcase, 2 tvs, 2 laptops, 97.0ms\n",
            "Speed: 3.4ms preprocess, 97.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  60%|██████    | 144/240 [00:44<00:27,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 suitcase, 2 tvs, 1 laptop, 95.6ms\n",
            "Speed: 5.7ms preprocess, 95.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  60%|██████    | 145/240 [00:45<00:26,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 2 tvs, 1 laptop, 1 mouse, 95.2ms\n",
            "Speed: 4.0ms preprocess, 95.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  61%|██████    | 146/240 [00:45<00:26,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 tv, 1 laptop, 1 mouse, 111.1ms\n",
            "Speed: 6.0ms preprocess, 111.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  61%|██████▏   | 147/240 [00:45<00:26,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 cup, 3 tvs, 1 laptop, 1 mouse, 118.6ms\n",
            "Speed: 3.8ms preprocess, 118.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  62%|██████▏   | 148/240 [00:45<00:26,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 cup, 3 tvs, 2 laptops, 104.9ms\n",
            "Speed: 3.1ms preprocess, 104.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  62%|██████▏   | 149/240 [00:46<00:25,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 111.1ms\n",
            "Speed: 3.3ms preprocess, 111.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  62%|██████▎   | 150/240 [00:46<00:25,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 handbag, 1 suitcase, 3 tvs, 89.4ms\n",
            "Speed: 3.4ms preprocess, 89.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  63%|██████▎   | 151/240 [00:46<00:25,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 105.7ms\n",
            "Speed: 3.2ms preprocess, 105.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  63%|██████▎   | 152/240 [00:47<00:24,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 suitcase, 3 chairs, 3 tvs, 1 laptop, 126.5ms\n",
            "Speed: 4.6ms preprocess, 126.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  64%|██████▍   | 153/240 [00:47<00:25,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 backpack, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 112.1ms\n",
            "Speed: 5.3ms preprocess, 112.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  64%|██████▍   | 154/240 [00:47<00:25,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 104.8ms\n",
            "Speed: 4.2ms preprocess, 104.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  65%|██████▍   | 155/240 [00:48<00:24,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 suitcase, 1 chair, 3 tvs, 2 laptops, 2 mouses, 117.4ms\n",
            "Speed: 3.7ms preprocess, 117.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  65%|██████▌   | 156/240 [00:48<00:24,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 suitcase, 3 tvs, 2 laptops, 2 mouses, 97.2ms\n",
            "Speed: 4.4ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  65%|██████▌   | 157/240 [00:48<00:24,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 suitcase, 2 chairs, 2 tvs, 1 laptop, 1 mouse, 89.0ms\n",
            "Speed: 3.4ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  66%|██████▌   | 158/240 [00:48<00:23,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 2 chairs, 1 tv, 1 laptop, 1 mouse, 89.1ms\n",
            "Speed: 3.3ms preprocess, 89.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  66%|██████▋   | 159/240 [00:49<00:23,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 1 mouse, 112.6ms\n",
            "Speed: 2.9ms preprocess, 112.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  67%|██████▋   | 160/240 [00:49<00:22,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 1 mouse, 115.7ms\n",
            "Speed: 4.2ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  67%|██████▋   | 161/240 [00:49<00:22,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 3 tvs, 1 laptop, 148.9ms\n",
            "Speed: 3.3ms preprocess, 148.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  68%|██████▊   | 162/240 [00:50<00:23,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 162.2ms\n",
            "Speed: 4.7ms preprocess, 162.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  68%|██████▊   | 163/240 [00:50<00:25,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 3 tvs, 1 laptop, 163.9ms\n",
            "Speed: 9.0ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  68%|██████▊   | 164/240 [00:50<00:26,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 2 persons, 1 handbag, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 132.3ms\n",
            "Speed: 6.4ms preprocess, 132.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  69%|██████▉   | 165/240 [00:51<00:26,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 3 tvs, 1 laptop, 141.1ms\n",
            "Speed: 3.8ms preprocess, 141.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  69%|██████▉   | 166/240 [00:51<00:27,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 136.1ms\n",
            "Speed: 3.4ms preprocess, 136.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  70%|██████▉   | 167/240 [00:51<00:26,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 2 chairs, 3 tvs, 1 laptop, 153.5ms\n",
            "Speed: 4.2ms preprocess, 153.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  70%|███████   | 168/240 [00:52<00:26,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 1 chair, 3 tvs, 1 laptop, 144.0ms\n",
            "Speed: 3.4ms preprocess, 144.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  70%|███████   | 169/240 [00:52<00:26,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 2 chairs, 2 tvs, 98.4ms\n",
            "Speed: 4.5ms preprocess, 98.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  71%|███████   | 170/240 [00:53<00:24,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 2 tvs, 2 laptops, 95.6ms\n",
            "Speed: 3.3ms preprocess, 95.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  71%|███████▏  | 171/240 [00:53<00:22,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 suitcase, 2 tvs, 1 laptop, 104.4ms\n",
            "Speed: 3.3ms preprocess, 104.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  72%|███████▏  | 172/240 [00:53<00:21,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 2 tvs, 2 laptops, 93.5ms\n",
            "Speed: 4.2ms preprocess, 93.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  72%|███████▏  | 173/240 [00:53<00:20,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 suitcase, 1 chair, 2 tvs, 1 laptop, 1 mouse, 87.9ms\n",
            "Speed: 5.9ms preprocess, 87.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  72%|███████▎  | 174/240 [00:54<00:19,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 2 chairs, 2 tvs, 2 laptops, 1 mouse, 95.6ms\n",
            "Speed: 4.0ms preprocess, 95.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  73%|███████▎  | 175/240 [00:54<00:18,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 suitcase, 2 chairs, 1 tv, 1 laptop, 1 mouse, 96.5ms\n",
            "Speed: 3.6ms preprocess, 96.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  73%|███████▎  | 176/240 [00:54<00:18,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 handbag, 1 suitcase, 3 chairs, 2 tvs, 2 laptops, 1 mouse, 97.6ms\n",
            "Speed: 3.8ms preprocess, 97.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  74%|███████▍  | 177/240 [00:54<00:18,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 suitcase, 1 chair, 1 tv, 1 laptop, 1 mouse, 94.0ms\n",
            "Speed: 4.3ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  74%|███████▍  | 178/240 [00:55<00:17,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 handbag, 1 suitcase, 1 cup, 2 laptops, 2 mouses, 98.6ms\n",
            "Speed: 4.1ms preprocess, 98.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  75%|███████▍  | 179/240 [00:55<00:17,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 tv, 1 laptop, 116.5ms\n",
            "Speed: 5.4ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  75%|███████▌  | 180/240 [00:55<00:17,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 2 tvs, 2 laptops, 97.5ms\n",
            "Speed: 5.4ms preprocess, 97.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  75%|███████▌  | 181/240 [00:56<00:17,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 2 chairs, 2 tvs, 114.3ms\n",
            "Speed: 5.3ms preprocess, 114.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  76%|███████▌  | 182/240 [00:56<00:16,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 1 tv, 1 laptop, 89.8ms\n",
            "Speed: 6.7ms preprocess, 89.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  76%|███████▋  | 183/240 [00:56<00:16,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 1 tv, 1 laptop, 113.9ms\n",
            "Speed: 4.1ms preprocess, 113.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  77%|███████▋  | 184/240 [00:57<00:16,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 1 chair, 1 tv, 1 laptop, 94.2ms\n",
            "Speed: 7.8ms preprocess, 94.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  77%|███████▋  | 185/240 [00:57<00:15,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 2 tvs, 1 laptop, 105.4ms\n",
            "Speed: 3.4ms preprocess, 105.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  78%|███████▊  | 186/240 [00:57<00:15,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 2 tvs, 1 laptop, 100.7ms\n",
            "Speed: 4.0ms preprocess, 100.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  78%|███████▊  | 187/240 [00:57<00:15,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 1 chair, 1 tv, 1 laptop, 99.5ms\n",
            "Speed: 3.5ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  78%|███████▊  | 188/240 [00:58<00:14,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 suitcase, 1 chair, 1 laptop, 113.1ms\n",
            "Speed: 3.7ms preprocess, 113.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  79%|███████▉  | 189/240 [00:58<00:14,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 6 persons, 1 handbag, 1 suitcase, 87.7ms\n",
            "Speed: 3.5ms preprocess, 87.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  79%|███████▉  | 190/240 [00:58<00:14,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 suitcase, 1 chair, 101.1ms\n",
            "Speed: 3.1ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  80%|███████▉  | 191/240 [00:59<00:14,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 backpack, 1 handbag, 1 suitcase, 1 tv, 1 laptop, 100.8ms\n",
            "Speed: 3.2ms preprocess, 100.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  80%|████████  | 192/240 [00:59<00:13,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 chair, 1 laptop, 98.6ms\n",
            "Speed: 3.6ms preprocess, 98.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  80%|████████  | 193/240 [00:59<00:13,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 7 persons, 1 handbag, 1 suitcase, 1 laptop, 94.7ms\n",
            "Speed: 3.9ms preprocess, 94.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  81%|████████  | 194/240 [00:59<00:12,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 suitcase, 1 chair, 1 tv, 1 laptop, 101.1ms\n",
            "Speed: 3.4ms preprocess, 101.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  81%|████████▏ | 195/240 [01:00<00:12,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 111.9ms\n",
            "Speed: 3.3ms preprocess, 111.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  82%|████████▏ | 196/240 [01:00<00:12,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 1 suitcase, 1 laptop, 1 book, 92.2ms\n",
            "Speed: 3.7ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  82%|████████▏ | 197/240 [01:00<00:12,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 1 suitcase, 108.1ms\n",
            "Speed: 3.0ms preprocess, 108.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  82%|████████▎ | 198/240 [01:01<00:12,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 98.2ms\n",
            "Speed: 3.8ms preprocess, 98.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  83%|████████▎ | 199/240 [01:01<00:11,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 95.7ms\n",
            "Speed: 3.4ms preprocess, 95.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  83%|████████▎ | 200/240 [01:01<00:11,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 97.8ms\n",
            "Speed: 3.3ms preprocess, 97.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  84%|████████▍ | 201/240 [01:01<00:11,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 104.2ms\n",
            "Speed: 3.4ms preprocess, 104.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  84%|████████▍ | 202/240 [01:02<00:10,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 97.4ms\n",
            "Speed: 3.4ms preprocess, 97.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  85%|████████▍ | 203/240 [01:02<00:10,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 97.8ms\n",
            "Speed: 3.6ms preprocess, 97.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  85%|████████▌ | 204/240 [01:02<00:10,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 handbag, 140.6ms\n",
            "Speed: 8.3ms preprocess, 140.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  85%|████████▌ | 205/240 [01:03<00:10,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 handbag, 147.4ms\n",
            "Speed: 3.1ms preprocess, 147.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  86%|████████▌ | 206/240 [01:03<00:11,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 129.6ms\n",
            "Speed: 3.3ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  86%|████████▋ | 207/240 [01:03<00:11,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 cup, 1 dining table, 1 tv, 156.3ms\n",
            "Speed: 11.4ms preprocess, 156.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  87%|████████▋ | 208/240 [01:04<00:11,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 cup, 1 tv, 148.0ms\n",
            "Speed: 4.6ms preprocess, 148.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  87%|████████▋ | 209/240 [01:04<00:11,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 cup, 144.7ms\n",
            "Speed: 4.0ms preprocess, 144.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  88%|████████▊ | 210/240 [01:04<00:11,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 tv, 171.4ms\n",
            "Speed: 3.5ms preprocess, 171.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  88%|████████▊ | 211/240 [01:05<00:11,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 cup, 1 dining table, 124.8ms\n",
            "Speed: 3.2ms preprocess, 124.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  88%|████████▊ | 212/240 [01:05<00:10,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 cup, 1 chair, 1 dining table, 98.6ms\n",
            "Speed: 3.9ms preprocess, 98.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  89%|████████▉ | 213/240 [01:06<00:09,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 cup, 1 dining table, 87.0ms\n",
            "Speed: 3.6ms preprocess, 87.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  89%|████████▉ | 214/240 [01:06<00:08,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 1 book, 97.2ms\n",
            "Speed: 3.4ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  90%|████████▉ | 215/240 [01:06<00:07,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 chair, 1 dining table, 103.0ms\n",
            "Speed: 2.9ms preprocess, 103.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  90%|█████████ | 216/240 [01:06<00:07,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 105.3ms\n",
            "Speed: 2.9ms preprocess, 105.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  90%|█████████ | 217/240 [01:07<00:06,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 119.5ms\n",
            "Speed: 3.6ms preprocess, 119.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  91%|█████████ | 218/240 [01:07<00:06,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 94.1ms\n",
            "Speed: 6.6ms preprocess, 94.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  91%|█████████▏| 219/240 [01:07<00:06,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 96.4ms\n",
            "Speed: 3.3ms preprocess, 96.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  92%|█████████▏| 220/240 [01:07<00:05,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 98.4ms\n",
            "Speed: 3.9ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  92%|█████████▏| 221/240 [01:08<00:05,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 90.8ms\n",
            "Speed: 3.6ms preprocess, 90.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  92%|█████████▎| 222/240 [01:08<00:05,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 1 book, 90.8ms\n",
            "Speed: 7.6ms preprocess, 90.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  93%|█████████▎| 223/240 [01:08<00:04,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 103.8ms\n",
            "Speed: 3.6ms preprocess, 103.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  93%|█████████▎| 224/240 [01:09<00:04,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 1 book, 135.0ms\n",
            "Speed: 4.3ms preprocess, 135.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  94%|█████████▍| 225/240 [01:09<00:04,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 5 persons, 1 bottle, 1 dining table, 1 book, 89.6ms\n",
            "Speed: 3.2ms preprocess, 89.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  94%|█████████▍| 226/240 [01:09<00:04,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 107.1ms\n",
            "Speed: 3.3ms preprocess, 107.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  95%|█████████▍| 227/240 [01:10<00:03,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 refrigerator, 1 book, 102.9ms\n",
            "Speed: 3.2ms preprocess, 102.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  95%|█████████▌| 228/240 [01:10<00:03,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 refrigerator, 1 book, 101.5ms\n",
            "Speed: 3.4ms preprocess, 101.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  95%|█████████▌| 229/240 [01:10<00:03,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 refrigerator, 1 book, 91.1ms\n",
            "Speed: 3.6ms preprocess, 91.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  96%|█████████▌| 230/240 [01:10<00:02,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 refrigerator, 1 book, 92.7ms\n",
            "Speed: 5.9ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  96%|█████████▋| 231/240 [01:11<00:02,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 refrigerator, 1 book, 120.3ms\n",
            "Speed: 2.9ms preprocess, 120.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  97%|█████████▋| 232/240 [01:11<00:02,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 91.9ms\n",
            "Speed: 3.4ms preprocess, 91.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  97%|█████████▋| 233/240 [01:11<00:01,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 86.2ms\n",
            "Speed: 3.4ms preprocess, 86.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  98%|█████████▊| 234/240 [01:12<00:01,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 1 book, 96.0ms\n",
            "Speed: 4.7ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  98%|█████████▊| 235/240 [01:12<00:01,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 chair, 1 dining table, 1 book, 130.6ms\n",
            "Speed: 3.4ms preprocess, 130.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  98%|█████████▊| 236/240 [01:12<00:01,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 98.2ms\n",
            "Speed: 5.7ms preprocess, 98.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  99%|█████████▉| 237/240 [01:12<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 88.6ms\n",
            "Speed: 4.5ms preprocess, 88.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames:  99%|█████████▉| 238/240 [01:13<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 4 persons, 1 bottle, 1 dining table, 1 book, 103.4ms\n",
            "Speed: 3.7ms preprocess, 103.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing frames: 100%|█████████▉| 239/240 [01:13<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 3 persons, 1 bottle, 1 couch, 1 dining table, 1 book, 87.4ms\n",
            "Speed: 3.9ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing frames: 100%|██████████| 240/240 [01:13<00:00,  3.25it/s]\n",
            "ERROR:root:An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n",
            "2024-12-12 19:58:46,668 - ERROR - An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n",
            "2024-12-12 19:58:46,668 - ERROR - An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n",
            "2024-12-12 19:58:46,668 - ERROR - An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n",
            "2024-12-12 19:58:46,668 - ERROR - An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n",
            "2024-12-12 19:58:46,668 - ERROR - An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n",
            "2024-12-12 19:58:46,668 - ERROR - An error occurred: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Ist future work need to show accuracy as percentage\n",
        " # 2nd Future work\n",
        "import os\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Setup Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when the app runs\n",
        "\n",
        "# Paths\n",
        "UPLOAD_FOLDER = '/content/uploads/'\n",
        "RESULT_FOLDER = '/content/results/'\n",
        "MODEL_PATH = '/content/drive/MyDrive/royal_detector.pt'  # Update this to your model's path\n",
        "\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(RESULT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# Home Page\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return '''\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>Royal Detection</title>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>Royal Detection - Upload an Image</h1>\n",
        "        <form action=\"/upload\" method=\"POST\" enctype=\"multipart/form-data\">\n",
        "            <input type=\"file\" name=\"file\">\n",
        "            <button type=\"submit\">Upload</button>\n",
        "        </form>\n",
        "    </body>\n",
        "    </html>\n",
        "    '''\n",
        "\n",
        "# Upload and Process Image\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return \"No file part\"\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return \"No selected file\"\n",
        "    if file:\n",
        "        # Save the uploaded image\n",
        "        filepath = os.path.join(UPLOAD_FOLDER, file.filename)\n",
        "        file.save(filepath)\n",
        "\n",
        "        # Run YOLO on the image\n",
        "        results = model.predict(source=filepath, save=True, conf=0.25)\n",
        "\n",
        "        # Save the result image\n",
        "        result_filepath = os.path.join(RESULT_FOLDER, file.filename)\n",
        "        results[0].save(save_dir=RESULT_FOLDER)\n",
        "\n",
        "        return f'''\n",
        "        <!DOCTYPE html>\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Royal Detection Result</title>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>Detection Result</h1>\n",
        "            <img src=\"/result/{file.filename}\" alt=\"Result Image\">\n",
        "            <br><br>\n",
        "            <a href=\"/\">Go Back</a>\n",
        "        </body>\n",
        "        </html>\n",
        "        '''\n",
        "\n",
        "# Serve Result Images\n",
        "@app.route('/result/<filename>')\n",
        "def result_file(filename):\n",
        "    return redirect(f'/content/results/{filename}')\n",
        "\n",
        "# Start the app\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Bu362C0HH7ir",
        "outputId": "047f9f0a-57fd-44ce-832d-a8d92098f2b2"
      },
      "id": "Bu362C0HH7ir",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'flask_ngrok'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ddce2765a15b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_ngrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_with_ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask_ngrok'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cdca0da",
      "metadata": {
        "id": "3cdca0da"
      },
      "source": [
        "## Model Description\n",
        "\n",
        "<img width=\"800\" alt=\"YOLO Model Comparison\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/yolo-comparison-plots.png\">\n",
        "\n",
        "Ultralytics YOLOv5 🚀 is a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility. YOLOv5 is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection, instance segmentation and image classification tasks.\n",
        "\n",
        "We hope that the resources here will help you get the most out of YOLOv5. Please browse the YOLOv5 [Docs](https://docs.ultralytics.com/yolov5) for details, raise an issue on [GitHub](https://github.com/ultralytics/yolov5/issues/new/choose) for support, and join our [Discord](https://discord.gg/n6cFeSPZdD) community for questions and discussions!\n",
        "\n",
        "| Model                                                                                           | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | mAP<sup>val<br>50 | Speed<br><sup>CPU b1<br>(ms) | Speed<br><sup>V100 b1<br>(ms) | Speed<br><sup>V100 b32<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>@640 (B) |\n",
        "|-------------------------------------------------------------------------------------------------|-----------------------|----------------------|-------------------|------------------------------|-------------------------------|--------------------------------|--------------------|------------------------|\n",
        "| [YOLOv5n](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt)              | 640                   | 28.0                 | 45.7              | **45**                       | **6.3**                       | **0.6**                        | **1.9**            | **4.5**                |\n",
        "| [YOLOv5s](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt)              | 640                   | 37.4                 | 56.8              | 98                           | 6.4                           | 0.9                            | 7.2                | 16.5                   |\n",
        "| [YOLOv5m](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt)              | 640                   | 45.4                 | 64.1              | 224                          | 8.2                           | 1.7                            | 21.2               | 49.0                   |\n",
        "| [YOLOv5l](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt)              | 640                   | 49.0                 | 67.3              | 430                          | 10.1                          | 2.7                            | 46.5               | 109.1                  |\n",
        "| [YOLOv5x](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt)              | 640                   | 50.7                 | 68.9              | 766                          | 12.1                          | 4.8                            | 86.7               | 205.7                  |\n",
        "|                                                                                                 |                       |                      |                   |                              |                               |                                |                    |                        |\n",
        "| [YOLOv5n6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n6.pt)            | 1280                  | 36.0                 | 54.4              | 153                          | 8.1                           | 2.1                            | 3.2                | 4.6                    |\n",
        "| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s6.pt)            | 1280                  | 44.8                 | 63.7              | 385                          | 8.2                           | 3.6                            | 12.6               | 16.8                   |\n",
        "| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m6.pt)            | 1280                  | 51.3                 | 69.3              | 887                          | 11.1                          | 6.8                            | 35.7               | 50.0                   |\n",
        "| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l6.pt)            | 1280                  | 53.7                 | 71.3              | 1784                         | 15.8                          | 10.5                           | 76.8               | 111.4                  |\n",
        "| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x6.pt)<br>+ [TTA] | 1280<br>1536          | 55.0<br>**55.8**     | 72.7<br>**72.7**  | 3136<br>-                    | 26.2<br>-                     | 19.4<br>-                      | 140.7<br>-         | 209.8<br>-             |\n",
        "\n",
        "<details>\n",
        "  <summary>Table Notes</summary>\n",
        "\n",
        "- All checkpoints are trained to 300 epochs with default settings. Nano and Small models use [hyp.scratch-low.yaml](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml) hyps, all others use [hyp.scratch-high.yaml](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-high.yaml).\n",
        "- **mAP<sup>val</sup>** values are for single-model single-scale on [COCO val2017](http://cocodataset.org) dataset.<br>Reproduce by `python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65`\n",
        "- **Speed** averaged over COCO val images using a [AWS p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/) instance. NMS times (~1 ms/img) not included.<br>Reproduce by `python val.py --data coco.yaml --img 640 --task speed --batch 1`\n",
        "- **TTA** [Test Time Augmentation](https://docs.ultralytics.com/yolov5/tutorials/test_time_augmentation) includes reflection and scale augmentations.<br>Reproduce by `python val.py --data coco.yaml --img 1536 --iou 0.7 --augment`\n",
        "\n",
        "</details>\n",
        "\n",
        "## Load From PyTorch Hub\n",
        "\n",
        "This example loads a pretrained **YOLOv5s** model and passes an image for inference. YOLOv5 accepts **URL**, **Filename**, **PIL**, **OpenCV**, **Numpy** and **PyTorch** inputs, and returns detections in **torch**, **pandas**, and **JSON** output formats. See the [YOLOv5 PyTorch Hub Tutorial](https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading/) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cfec8f1",
      "metadata": {
        "id": "4cfec8f1",
        "outputId": "703f3b8d-ad1e-49fd-a483-06a47481a6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2024-9-15 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file '/content/bus.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0bc33740ea27>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ims, size, augment, profile)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"image{i}\"\u001b[0m  \u001b[0;31m# filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filename or uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                     \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexif_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3283\u001b[0;31m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3285\u001b[0m         \u001b[0mndmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/content/bus.jpg'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Images\n",
        "imgs = ['/content/bus.jpg']  # batch of images\n",
        "\n",
        "# Inference\n",
        "results = model(imgs)\n",
        "\n",
        "# Results\n",
        "results.print()\n",
        "results.save()  # or .show()\n",
        "\n",
        "results.xyxy[0]  # img1 predictions (tensor)\n",
        "results.pandas().xyxy[0]  # img1 predictions (pandas)\n",
        "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
        "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
        "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
        "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
        "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec56a3f",
      "metadata": {
        "id": "2ec56a3f"
      },
      "source": [
        "## Citation\n",
        "\n",
        "If you use YOLOv5 or YOLOv5u in your research, please cite the Ultralytics YOLOv5 repository as follows:\n",
        "\n",
        "[![DOI](https://zenodo.org/badge/264818686.svg)](https://zenodo.org/badge/latestdoi/264818686)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f906aee7",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "f906aee7"
      },
      "outputs": [],
      "source": [
        "@software{yolov5,\n",
        "  title = {YOLOv5 by Ultralytics},\n",
        "  author = {Glenn Jocher},\n",
        "  year = {2020},\n",
        "  version = {7.0},\n",
        "  license = {AGPL-3.0},\n",
        "  url = {https://github.com/ultralytics/yolov5},\n",
        "  doi = {10.5281/zenodo.3908559},\n",
        "  orcid = {0000-0001-5950-6979}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7bf31c9",
      "metadata": {
        "id": "a7bf31c9"
      },
      "source": [
        "## Contact\n",
        "\n",
        "For YOLOv5 bug reports and feature requests please visit [GitHub Issues](https://github.com/ultralytics/yolov5/issues), and join our [Discord](https://discord.gg/n6cFeSPZdD) community for questions and discussions!\n",
        "\n",
        "&nbsp;"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}